#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ç¤ºä¾‹è„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æœ¬é¡¹ç›®è¿›è¡ŒQwenå¤§æ¨¡å‹å¾®è°ƒå’Œè¯„æµ‹
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from scripts.train import QwenTrainer
from scripts.evaluate import ModelEvaluator
from scripts.inference import QwenInference
from data.download_data import DatasetDownloader
from data.preprocess import DataPreprocessor


def example_1_basic_training():
    """
    ç¤ºä¾‹1: åŸºç¡€è®­ç»ƒæµç¨‹
    """
    print("\n=== ç¤ºä¾‹1: åŸºç¡€è®­ç»ƒæµç¨‹ ===")
    
    # 1. ä¸‹è½½æ•°æ®
    print("\næ­¥éª¤1: ä¸‹è½½æ•°æ®")
    downloader = DatasetDownloader()
    downloader.download_dataset("alpaca_gpt4_data")
    
    # 2. é¢„å¤„ç†æ•°æ®
    print("\næ­¥éª¤2: é¢„å¤„ç†æ•°æ®")
    preprocessor = DataPreprocessor()
    # è¿™é‡Œéœ€è¦å®é™…çš„æ•°æ®é›†è·¯å¾„
    # processed_dataset = preprocessor.preprocess_dataset(dataset)
    
    # 3. è®­ç»ƒæ¨¡å‹
    print("\næ­¥éª¤3: è®­ç»ƒæ¨¡å‹")
    trainer = QwenTrainer("config/training_config.yaml")
    # trainer.run()  # å®é™…è®­ç»ƒ
    
    print("åŸºç¡€è®­ç»ƒæµç¨‹ç¤ºä¾‹å®Œæˆ")


def example_2_custom_config():
    """
    ç¤ºä¾‹2: è‡ªå®šä¹‰é…ç½®è®­ç»ƒ
    """
    print("\n=== ç¤ºä¾‹2: è‡ªå®šä¹‰é…ç½®è®­ç»ƒ ===")
    
    # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
    custom_config = {
        'model': {
            'model_name_or_path': 'Qwen/Qwen-7B-Chat',
            'trust_remote_code': True,
            'torch_dtype': 'bfloat16'
        },
        'training': {
            'num_train_epochs': 2,
            'per_device_train_batch_size': 2,
            'learning_rate': 1e-5,
            'output_dir': './results/custom_checkpoints'
        },
        'lora': {
            'use_lora': True,
            'r': 8,
            'lora_alpha': 16
        }
    }
    
    print("è‡ªå®šä¹‰é…ç½®åˆ›å»ºå®Œæˆ")
    print(f"è®­ç»ƒè½®æ•°: {custom_config['training']['num_train_epochs']}")
    print(f"æ‰¹æ¬¡å¤§å°: {custom_config['training']['per_device_train_batch_size']}")
    print(f"å­¦ä¹ ç‡: {custom_config['training']['learning_rate']}")
    print(f"LoRA rank: {custom_config['lora']['r']}")


def example_3_batch_inference():
    """
    ç¤ºä¾‹3: æ‰¹é‡æ¨ç†
    """
    print("\n=== ç¤ºä¾‹3: æ‰¹é‡æ¨ç† ===")
    
    # æ¨¡æ‹Ÿå·²è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
    model_path = "./results/checkpoints"
    
    if not Path(model_path).exists():
        print(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ")
        return
    
    # åˆå§‹åŒ–æ¨ç†å™¨
    # inference = QwenInference(model_path)
    
    # æ‰¹é‡æ¨ç†ç¤ºä¾‹
    test_inputs = [
        "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "å¦‚ä½•æé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯Transformeræ¶æ„ï¼Ÿ",
        "è¯·ä»‹ç»ä¸€ä¸‹æ³¨æ„åŠ›æœºåˆ¶ã€‚",
        "å¦‚ä½•é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼Ÿ"
    ]
    
    print(f"å‡†å¤‡è¿›è¡Œæ‰¹é‡æ¨ç†ï¼Œå…± {len(test_inputs)} ä¸ªé—®é¢˜")
    
    # responses = inference.batch_inference(test_inputs)
    
    # æ˜¾ç¤ºç»“æœ
    # for i, (question, answer) in enumerate(zip(test_inputs, responses), 1):
    #     print(f"\né—®é¢˜ {i}: {question}")
    #     print(f"å›ç­”: {answer}")
    
    print("æ‰¹é‡æ¨ç†ç¤ºä¾‹å‡†å¤‡å®Œæˆ")


def example_4_comprehensive_evaluation():
    """
    ç¤ºä¾‹4: ç»¼åˆè¯„æµ‹
    """
    print("\n=== ç¤ºä¾‹4: ç»¼åˆè¯„æµ‹ ===")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    model_path = "./results/checkpoints"
    if not Path(model_path).exists():
        print(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ")
        return
    
    # åˆå§‹åŒ–è¯„æµ‹å™¨
    # evaluator = ModelEvaluator("config/eval_config.yaml")
    
    # è¿è¡Œè¯„æµ‹
    # evaluator.run_evaluation()
    
    print("ç»¼åˆè¯„æµ‹ç¤ºä¾‹å‡†å¤‡å®Œæˆ")
    print("è¯„æµ‹å°†åŒ…æ‹¬ä»¥ä¸‹æŒ‡æ ‡:")
    print("- BLEUåˆ†æ•°")
    print("- ROUGEåˆ†æ•°")
    print("- BERTScore")
    print("- å›°æƒ‘åº¦")
    print("- å¤šæ ·æ€§æŒ‡æ ‡")


def example_5_interactive_demo():
    """
    ç¤ºä¾‹5: äº¤äº’å¼æ¼”ç¤º
    """
    print("\n=== ç¤ºä¾‹5: äº¤äº’å¼æ¼”ç¤º ===")
    
    # æ¨¡æ‹Ÿäº¤äº’å¼å¯¹è¯
    conversation_examples = [
        {
            "user": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚",
            "assistant": "ä½ å¥½ï¼æˆ‘æ˜¯åŸºäºQwenæ¶æ„å¾®è°ƒçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºäº†æ›´å¥½åœ°ç†è§£å’Œå›åº”ä¸­æ–‡å¯¹è¯è€Œè®­ç»ƒã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯äº¤æµã€æä¾›ä¿¡æ¯ç­‰ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
        },
        {
            "user": "è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ",
            "assistant": "å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰æ˜¯ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„äººå·¥æ™ºèƒ½æ¨¡å‹ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n\n1. **è§„æ¨¡åºå¤§**: é€šå¸¸åŒ…å«æ•°åäº¿åˆ°æ•°åƒäº¿ä¸ªå‚æ•°\n2. **é¢„è®­ç»ƒ**: åœ¨å¤§é‡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œæ— ç›‘ç£å­¦ä¹ \n3. **é€šç”¨èƒ½åŠ›**: å¯ä»¥å¤„ç†å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡\n4. **æ¶Œç°èƒ½åŠ›**: åœ¨è¾¾åˆ°ä¸€å®šè§„æ¨¡åå±•ç°å‡ºæ„æƒ³ä¸åˆ°çš„èƒ½åŠ›\n\nä»£è¡¨æ€§çš„å¤§è¯­è¨€æ¨¡å‹åŒ…æ‹¬GPTç³»åˆ—ã€BERTã€T5ã€PaLMç­‰ã€‚è¿™äº›æ¨¡å‹é€šè¿‡å­¦ä¹ äººç±»è¯­è¨€çš„æ¨¡å¼å’Œè§„å¾‹ï¼Œèƒ½å¤Ÿç”Ÿæˆè¿è´¯ã€æœ‰æ„ä¹‰çš„æ–‡æœ¬ã€‚"
        },
        {
            "user": "å¦‚ä½•è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Ÿ",
            "assistant": "è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½é€šå¸¸ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦è¿›è¡Œï¼š\n\n**è‡ªåŠ¨è¯„æµ‹æŒ‡æ ‡:**\n- BLEU: è¡¡é‡ç”Ÿæˆæ–‡æœ¬ä¸å‚è€ƒæ–‡æœ¬çš„ç›¸ä¼¼åº¦\n- ROUGE: ä¸»è¦ç”¨äºæ‘˜è¦ä»»åŠ¡çš„è¯„ä¼°\n- BERTScore: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„è¯„æµ‹\n- å›°æƒ‘åº¦(Perplexity): è¡¡é‡æ¨¡å‹å¯¹æ–‡æœ¬çš„é¢„æµ‹èƒ½åŠ›\n\n**ä»»åŠ¡ç‰¹å®šè¯„æµ‹:**\n- é—®ç­”å‡†ç¡®ç‡\n- æ–‡æœ¬åˆ†ç±»F1åˆ†æ•°\n- ä»£ç ç”Ÿæˆé€šè¿‡ç‡\n- æ•°å­¦æ¨ç†æ­£ç¡®ç‡\n\n**äººå·¥è¯„ä¼°:**\n- æµç•…æ€§\n- ç›¸å…³æ€§\n- æœ‰ç”¨æ€§\n- å®‰å…¨æ€§\n\næœ¬é¡¹ç›®å®ç°äº†å¤šç§è‡ªåŠ¨è¯„æµ‹æŒ‡æ ‡ï¼Œå¯ä»¥å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚"
        }
    ]
    
    print("äº¤äº’å¼å¯¹è¯ç¤ºä¾‹:")
    for i, turn in enumerate(conversation_examples, 1):
        print(f"\n--- å¯¹è¯è½®æ¬¡ {i} ---")
        print(f"ç”¨æˆ·: {turn['user']}")
        print(f"åŠ©æ‰‹: {turn['assistant']}")
    
    print("\nè¦å¯åŠ¨çœŸå®çš„äº¤äº’å¼å¯¹è¯ï¼Œè¯·è¿è¡Œ:")
    print("python scripts/inference.py --model-path ./results/checkpoints --interactive")


def example_6_data_analysis():
    """
    ç¤ºä¾‹6: æ•°æ®åˆ†æ
    """
    print("\n=== ç¤ºä¾‹6: æ•°æ®åˆ†æ ===")
    
    # æ¨¡æ‹Ÿæ•°æ®ç»Ÿè®¡
    dataset_stats = {
        "alpaca_gpt4_data": {
            "samples": 52000,
            "avg_length": 256,
            "language": "English",
            "type": "Instruction-following"
        },
        "oasst1": {
            "samples": 161000,
            "avg_length": 312,
            "language": "Multilingual",
            "type": "Conversational"
        },
        "chinese_alpaca": {
            "samples": 52000,
            "avg_length": 198,
            "language": "Chinese",
            "type": "Instruction-following"
        }
    }
    
    print("æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
    print(f"{'æ•°æ®é›†':<20} {'æ ·æœ¬æ•°':<10} {'å¹³å‡é•¿åº¦':<10} {'è¯­è¨€':<12} {'ç±»å‹'}")
    print("-" * 70)
    
    for name, stats in dataset_stats.items():
        print(f"{name:<20} {stats['samples']:<10} {stats['avg_length']:<10} {stats['language']:<12} {stats['type']}")
    
    total_samples = sum(stats['samples'] for stats in dataset_stats.values())
    print(f"\næ€»æ ·æœ¬æ•°: {total_samples:,}")
    
    print("\næ•°æ®åˆ†å¸ƒå»ºè®®:")
    print("- è®­ç»ƒé›†: 90% (ç”¨äºæ¨¡å‹å­¦ä¹ )")
    print("- éªŒè¯é›†: 5% (ç”¨äºè¶…å‚æ•°è°ƒä¼˜)")
    print("- æµ‹è¯•é›†: 5% (ç”¨äºæœ€ç»ˆè¯„ä¼°)")


def example_7_monitoring_and_logging():
    """
    ç¤ºä¾‹7: ç›‘æ§å’Œæ—¥å¿—
    """
    print("\n=== ç¤ºä¾‹7: ç›‘æ§å’Œæ—¥å¿— ===")
    
    print("è®­ç»ƒç›‘æ§å·¥å…·:")
    print("1. TensorBoard: å®æ—¶æŸ¥çœ‹è®­ç»ƒæŒ‡æ ‡")
    print("   å¯åŠ¨å‘½ä»¤: tensorboard --logdir ./results/logs")
    print("   è®¿é—®åœ°å€: http://localhost:6006")
    
    print("\n2. Weights & Biases (å¯é€‰):")
    print("   - åœ¨çº¿å®éªŒè·Ÿè¸ª")
    print("   - è¶…å‚æ•°ä¼˜åŒ–")
    print("   - æ¨¡å‹ç‰ˆæœ¬ç®¡ç†")
    
    print("\nå…³é”®ç›‘æ§æŒ‡æ ‡:")
    monitoring_metrics = [
        "è®­ç»ƒæŸå¤± (Training Loss)",
        "éªŒè¯æŸå¤± (Validation Loss)",
        "å­¦ä¹ ç‡ (Learning Rate)",
        "æ¢¯åº¦èŒƒæ•° (Gradient Norm)",
        "GPUå†…å­˜ä½¿ç”¨ç‡",
        "è®­ç»ƒé€Ÿåº¦ (Samples/sec)"
    ]
    
    for i, metric in enumerate(monitoring_metrics, 1):
        print(f"   {i}. {metric}")
    
    print("\næ—¥å¿—æ–‡ä»¶ä½ç½®:")
    print("- è®­ç»ƒæ—¥å¿—: ./results/logs/training.log")
    print("- è¯„æµ‹æ—¥å¿—: ./results/evaluation/evaluation.log")
    print("- ç³»ç»Ÿæ—¥å¿—: ./results/logs/system.log")


def main():
    """
    ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    """
    print("ğŸš€ Qwenå¤§æ¨¡å‹å¾®è°ƒé¡¹ç›®ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    examples = [
        example_1_basic_training,
        example_2_custom_config,
        example_3_batch_inference,
        example_4_comprehensive_evaluation,
        example_5_interactive_demo,
        example_6_data_analysis,
        example_7_monitoring_and_logging
    ]
    
    for example_func in examples:
        try:
            example_func()
        except Exception as e:
            print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå‡ºé”™: {str(e)}")
    
    print("\n" + "=" * 50)
    print("ğŸ“š æ›´å¤šä¿¡æ¯:")
    print("- é¡¹ç›®æ–‡æ¡£: README.md")
    print("- é…ç½®è¯´æ˜: config/")
    print("- è„šæœ¬ä½¿ç”¨: scripts/")
    print("- å¿«é€Ÿå¼€å§‹: python quick_start.py --help")
    
    print("\nğŸ¯ æ¨èçš„ä½¿ç”¨æµç¨‹:")
    print("1. python quick_start.py --status          # æ£€æŸ¥é¡¹ç›®çŠ¶æ€")
    print("2. python quick_start.py --install         # å®‰è£…ä¾èµ–")
    print("3. python quick_start.py --download        # ä¸‹è½½æ•°æ®")
    print("4. python quick_start.py --preprocess      # é¢„å¤„ç†æ•°æ®")
    print("5. python quick_start.py --train           # è®­ç»ƒæ¨¡å‹")
    print("6. python quick_start.py --evaluate        # è¯„æµ‹æ¨¡å‹")
    print("7. python scripts/inference.py --interactive  # äº¤äº’å¼å¯¹è¯")
    
    print("\næˆ–è€…ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹:")
    print("python quick_start.py --full")


if __name__ == "__main__":
    main()