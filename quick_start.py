#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå¼€å§‹è„šæœ¬
ä¸€é”®è¿è¡ŒQwenå¤§æ¨¡å‹å¾®è°ƒå’Œè¯„æµ‹çš„å®Œæ•´æµç¨‹
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path
from typing import List, Optional

import yaml
from tqdm import tqdm


class QuickStart:
    """å¿«é€Ÿå¼€å§‹ç®¡ç†å™¨"""
    
    def __init__(self, project_dir: str = "."):
        self.project_dir = Path(project_dir)
        self.scripts_dir = self.project_dir / "scripts"
        self.data_dir = self.project_dir / "data"
        self.config_dir = self.project_dir / "config"
        
        # æ£€æŸ¥é¡¹ç›®ç»“æ„
        self.check_project_structure()
    
    def check_project_structure(self):
        """æ£€æŸ¥é¡¹ç›®ç»“æ„"""
        required_dirs = ["scripts", "data", "config", "models", "results"]
        required_files = [
            "config/training_config.yaml",
            "config/eval_config.yaml",
            "scripts/train.py",
            "scripts/evaluate.py",
            "scripts/inference.py",
            "data/download_data.py",
            "data/preprocess.py"
        ]
        
        print("æ£€æŸ¥é¡¹ç›®ç»“æ„...")
        
        # æ£€æŸ¥ç›®å½•
        for dir_name in required_dirs:
            dir_path = self.project_dir / dir_name
            if not dir_path.exists():
                print(f"[ERROR] ç¼ºå°‘ç›®å½•: {dir_name}")
                return False
            else:
                print(f"[OK] ç›®å½•å­˜åœ¨: {dir_name}")
        
        # æ£€æŸ¥æ–‡ä»¶
        for file_path in required_files:
            full_path = self.project_dir / file_path
            if not full_path.exists():
                print(f"[ERROR] ç¼ºå°‘æ–‡ä»¶: {file_path}")
                return False
            else:
                print(f"[OK] æ–‡ä»¶å­˜åœ¨: {file_path}")
        
        print("[SUCCESS] é¡¹ç›®ç»“æ„æ£€æŸ¥é€šè¿‡")
        return True
    
    def run_command(self, command: List[str], description: str, cwd: Optional[Path] = None) -> bool:
        """è¿è¡Œå‘½ä»¤"""
        print(f"\nğŸš€ {description}")
        print(f"å‘½ä»¤: {' '.join(command)}")
        
        try:
            # åœ¨Windowsä¸Šå¤„ç†ç¼–ç é—®é¢˜
            import locale
            system_encoding = locale.getpreferredencoding()
            
            result = subprocess.run(
                command,
                cwd=cwd or self.project_dir,
                check=True,
                capture_output=True,
                text=True,
                encoding=system_encoding,
                errors='replace'  # æ›¿æ¢æ— æ³•è§£ç çš„å­—ç¬¦
            )
            
            if result.stdout:
                print("è¾“å‡º:")
                print(result.stdout)
            
            print(f"[SUCCESS] {description} å®Œæˆ")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"[ERROR] {description} å¤±è´¥")
            print(f"é”™è¯¯ä»£ç : {e.returncode}")
            if e.stdout:
                print("æ ‡å‡†è¾“å‡º:")
                print(e.stdout)
            if e.stderr:
                print("é”™è¯¯è¾“å‡º:")
                print(e.stderr)
            return False
        
        except Exception as e:
            print(f"[ERROR] {description} å‡ºç°å¼‚å¸¸: {str(e)}")
            return False
    
    def install_dependencies(self) -> bool:
        """å®‰è£…ä¾èµ–"""
        requirements_file = self.project_dir / "requirements.txt"
        if not requirements_file.exists():
            print("[ERROR] requirements.txt ä¸å­˜åœ¨")
            return False
        
        return self.run_command(
            [sys.executable, "-m", "pip", "install", "-r", "requirements.txt"],
            "å®‰è£…Pythonä¾èµ–åŒ…"
        )
    
    def download_data(self, datasets: Optional[List[str]] = None) -> bool:
        """ä¸‹è½½æ•°æ®"""
        command = [sys.executable, "data/download_data.py"]
        
        if datasets:
            command.extend(["--datasets"] + datasets)
        else:
            # ä½¿ç”¨æ¨èçš„æ•°æ®é›†
            command.append("--datasets")
            command.extend(["alpaca_gpt4_data", "oasst1", "chinese_alpaca"])
        
        return self.run_command(command, "ä¸‹è½½è®­ç»ƒæ•°æ®é›†")
    
    def preprocess_data(self) -> bool:
        """é¢„å¤„ç†æ•°æ®"""
        return self.run_command(
            [sys.executable, "data/preprocess.py"],
            "é¢„å¤„ç†è®­ç»ƒæ•°æ®"
        )
    
    def train_model(self, config_file: str = "config/training_config.yaml") -> bool:
        """è®­ç»ƒæ¨¡å‹"""
        return self.run_command(
            [sys.executable, "scripts/train.py", "--config", config_file],
            "è®­ç»ƒQwenæ¨¡å‹"
        )
    
    def evaluate_model(self, config_file: str = "config/eval_config.yaml") -> bool:
        """è¯„æµ‹æ¨¡å‹"""
        return self.run_command(
            [sys.executable, "scripts/evaluate.py", "--config", config_file],
            "è¯„æµ‹æ¨¡å‹æ€§èƒ½"
        )
    
    def test_inference(self, model_path: str = "./results/checkpoints") -> bool:
        """æµ‹è¯•æ¨ç†"""
        test_input = "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²ã€‚"
        
        return self.run_command(
            [sys.executable, "scripts/inference.py", "--model-path", model_path, "--input", test_input],
            "æµ‹è¯•æ¨¡å‹æ¨ç†"
        )
    
    def run_full_pipeline(self, 
                         skip_install: bool = False,
                         skip_download: bool = False,
                         skip_preprocess: bool = False,
                         skip_train: bool = False,
                         skip_eval: bool = False,
                         datasets: Optional[List[str]] = None) -> bool:
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        print("\n" + "=" * 60)
        print("[START] å¼€å§‹Qwenå¤§æ¨¡å‹å¾®è°ƒå®Œæ•´æµç¨‹")
        print("=" * 60)
        
        steps = [
            ("install_dependencies", "å®‰è£…ä¾èµ–", not skip_install),
            ("download_data", "ä¸‹è½½æ•°æ®", not skip_download),
            ("preprocess_data", "é¢„å¤„ç†æ•°æ®", not skip_preprocess),
            ("train_model", "è®­ç»ƒæ¨¡å‹", not skip_train),
            ("evaluate_model", "è¯„æµ‹æ¨¡å‹", not skip_eval),
            ("test_inference", "æµ‹è¯•æ¨ç†", True)
        ]
        
        for i, (method_name, description, should_run) in enumerate(steps, 1):
            if not should_run:
                print(f"\n[SKIP] æ­¥éª¤ {i}: {description} (è·³è¿‡)")
                continue
            
            print(f"\n[STEP] æ­¥éª¤ {i}/{len([s for s in steps if s[2]])}: {description}")
            
            if method_name == "download_data":
                success = self.download_data(datasets)
            else:
                method = getattr(self, method_name)
                success = method()
            
            if not success:
                print(f"\n[ERROR] æµç¨‹åœ¨æ­¥éª¤ '{description}' å¤±è´¥")
                return False
        
        print("\n" + "=" * 60)
        print("[SUCCESS] å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
        print("=" * 60)
        
        # æ˜¾ç¤ºç»“æœä½ç½®
        print("\nğŸ“ ç»“æœæ–‡ä»¶ä½ç½®:")
        print(f"  - è®­ç»ƒæ¨¡å‹: ./results/checkpoints/")
        print(f"  - è®­ç»ƒæ—¥å¿—: ./results/logs/")
        print(f"  - è¯„æµ‹ç»“æœ: ./results/evaluation/")
        
        # æ˜¾ç¤ºä¸‹ä¸€æ­¥æ“ä½œ
        print("\nğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("  1. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—: tensorboard --logdir ./results/logs")
        print("  2. äº¤äº’å¼å¯¹è¯: python scripts/inference.py --model-path ./results/checkpoints --interactive")
        print("  3. æŸ¥çœ‹è¯„æµ‹æŠ¥å‘Š: æ‰“å¼€ ./results/evaluation/evaluation_report.html")
        
        return True
    
    def create_custom_config(self, 
                           model_name: str = "Qwen/Qwen-7B-Chat",
                           epochs: int = 3,
                           batch_size: int = 4,
                           learning_rate: float = 2e-5) -> bool:
        """åˆ›å»ºè‡ªå®šä¹‰é…ç½®"""
        print("\nğŸ“ åˆ›å»ºè‡ªå®šä¹‰è®­ç»ƒé…ç½®...")
        
        # è¯»å–é»˜è®¤é…ç½®
        config_file = self.config_dir / "training_config.yaml"
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # æ›´æ–°é…ç½®
        config['model']['model_name_or_path'] = model_name
        config['training']['num_train_epochs'] = epochs
        config['training']['per_device_train_batch_size'] = batch_size
        config['training']['learning_rate'] = learning_rate
        
        # ä¿å­˜è‡ªå®šä¹‰é…ç½®
        custom_config_file = self.config_dir / "custom_training_config.yaml"
        with open(custom_config_file, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, ensure_ascii=False, indent=2)
        
        print(f"[SUCCESS] è‡ªå®šä¹‰é…ç½®å·²ä¿å­˜åˆ°: {custom_config_file}")
        return True
    
    def show_status(self):
        """æ˜¾ç¤ºé¡¹ç›®çŠ¶æ€"""
        print("\nğŸ“Š é¡¹ç›®çŠ¶æ€æ£€æŸ¥")
        print("-" * 40)
        
        # æ£€æŸ¥æ•°æ®
        data_cache = self.data_dir / "cache"
        processed_data = self.data_dir / "processed" / "final_dataset"
        
        print(f"æ•°æ®ç¼“å­˜ç›®å½•: {'[OK]' if data_cache.exists() else '[MISSING]'} {data_cache}")
        print(f"é¢„å¤„ç†æ•°æ®: {'[OK]' if processed_data.exists() else '[MISSING]'} {processed_data}")
        
        # æ£€æŸ¥æ¨¡å‹
        model_dir = self.project_dir / "results" / "checkpoints"
        if model_dir.exists():
            checkpoints = list(model_dir.glob("checkpoint-*"))
            print(f"è®­ç»ƒæ£€æŸ¥ç‚¹: [OK] {len(checkpoints)} ä¸ªæ£€æŸ¥ç‚¹")
            if checkpoints:
                latest = max(checkpoints, key=lambda x: int(x.name.split('-')[1]))
                print(f"  æœ€æ–°æ£€æŸ¥ç‚¹: {latest.name}")
        else:
            print(f"è®­ç»ƒæ£€æŸ¥ç‚¹: [MISSING] æœªæ‰¾åˆ°")
        
        # æ£€æŸ¥è¯„æµ‹ç»“æœ
        eval_dir = self.project_dir / "results" / "evaluation"
        eval_report = eval_dir / "evaluation_report.html"
        print(f"è¯„æµ‹ç»“æœ: {'[OK]' if eval_report.exists() else '[MISSING]'} {eval_report}")
        
        # æ£€æŸ¥æ—¥å¿—
        log_dir = self.project_dir / "results" / "logs"
        if log_dir.exists():
            log_files = list(log_dir.glob("*.log"))
            print(f"è®­ç»ƒæ—¥å¿—: [OK] {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
        else:
            print(f"è®­ç»ƒæ—¥å¿—: [MISSING] æœªæ‰¾åˆ°")


def main():
    parser = argparse.ArgumentParser(description="Qwenå¤§æ¨¡å‹å¾®è°ƒå¿«é€Ÿå¼€å§‹")
    
    # ä¸»è¦æ“ä½œ
    parser.add_argument("--full", action="store_true", help="è¿è¡Œå®Œæ•´æµç¨‹")
    parser.add_argument("--install", action="store_true", help="ä»…å®‰è£…ä¾èµ–")
    parser.add_argument("--download", action="store_true", help="ä»…ä¸‹è½½æ•°æ®")
    parser.add_argument("--preprocess", action="store_true", help="ä»…é¢„å¤„ç†æ•°æ®")
    parser.add_argument("--train", action="store_true", help="ä»…è®­ç»ƒæ¨¡å‹")
    parser.add_argument("--evaluate", action="store_true", help="ä»…è¯„æµ‹æ¨¡å‹")
    parser.add_argument("--inference", action="store_true", help="ä»…æµ‹è¯•æ¨ç†")
    parser.add_argument("--status", action="store_true", help="æ˜¾ç¤ºé¡¹ç›®çŠ¶æ€")
    
    # è·³è¿‡é€‰é¡¹
    parser.add_argument("--skip-install", action="store_true", help="è·³è¿‡å®‰è£…ä¾èµ–")
    parser.add_argument("--skip-download", action="store_true", help="è·³è¿‡ä¸‹è½½æ•°æ®")
    parser.add_argument("--skip-preprocess", action="store_true", help="è·³è¿‡é¢„å¤„ç†")
    parser.add_argument("--skip-train", action="store_true", help="è·³è¿‡è®­ç»ƒ")
    parser.add_argument("--skip-eval", action="store_true", help="è·³è¿‡è¯„æµ‹")
    
    # é…ç½®é€‰é¡¹
    parser.add_argument("--datasets", nargs="+", help="æŒ‡å®šä¸‹è½½çš„æ•°æ®é›†")
    parser.add_argument("--model", default="Qwen/Qwen-7B-Chat", help="åŸºç¡€æ¨¡å‹åç§°")
    parser.add_argument("--epochs", type=int, default=3, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch-size", type=int, default=4, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--learning-rate", type=float, default=2e-5, help="å­¦ä¹ ç‡")
    parser.add_argument("--custom-config", action="store_true", help="åˆ›å»ºè‡ªå®šä¹‰é…ç½®")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å¿«é€Ÿå¼€å§‹ç®¡ç†å™¨
    quick_start = QuickStart()
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œç›¸åº”æ“ä½œ
    if args.status:
        quick_start.show_status()
    
    elif args.custom_config:
        quick_start.create_custom_config(
            model_name=args.model,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.learning_rate
        )
    
    elif args.full:
        quick_start.run_full_pipeline(
            skip_install=args.skip_install,
            skip_download=args.skip_download,
            skip_preprocess=args.skip_preprocess,
            skip_train=args.skip_train,
            skip_eval=args.skip_eval,
            datasets=args.datasets
        )
    
    elif args.install:
        quick_start.install_dependencies()
    
    elif args.download:
        quick_start.download_data(args.datasets)
    
    elif args.preprocess:
        quick_start.preprocess_data()
    
    elif args.train:
        quick_start.train_model()
    
    elif args.evaluate:
        quick_start.evaluate_model()
    
    elif args.inference:
        quick_start.test_inference()
    
    else:
        print("è¯·æŒ‡å®šè¦æ‰§è¡Œçš„æ“ä½œï¼Œä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©")
        print("\nå¸¸ç”¨å‘½ä»¤:")
        print("  python quick_start.py --full                    # è¿è¡Œå®Œæ•´æµç¨‹")
        print("  python quick_start.py --status                  # æŸ¥çœ‹é¡¹ç›®çŠ¶æ€")
        print("  python quick_start.py --custom-config           # åˆ›å»ºè‡ªå®šä¹‰é…ç½®")
        print("  python quick_start.py --full --skip-install     # è·³è¿‡å®‰è£…ä¾èµ–")


if __name__ == "__main__":
    main()