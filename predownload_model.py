#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹é¢„ä¸‹è½½è„šæœ¬
ä½¿ç”¨å¿«é€Ÿä¼ è¾“åŠŸèƒ½åŠ é€Ÿä¸‹è½½Qwen-7B-Chatæ¨¡å‹
"""

import os
import time
from transformers import AutoTokenizer, AutoModelForCausalLM
from huggingface_hub import snapshot_download

def setup_fast_download():
    """è®¾ç½®å¿«é€Ÿä¸‹è½½ç¯å¢ƒå˜é‡"""
    print("ğŸš€ è®¾ç½®å¿«é€Ÿä¸‹è½½ç¯å¢ƒ...")
    os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    print("âœ… ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ")
    print(f"   HF_HUB_ENABLE_HF_TRANSFER: {os.environ.get('HF_HUB_ENABLE_HF_TRANSFER')}")
    print(f"   HF_ENDPOINT: {os.environ.get('HF_ENDPOINT')}")

def download_model_fast():
    """ä½¿ç”¨å¿«é€Ÿæ–¹å¼ä¸‹è½½æ¨¡å‹"""
    model_name = "Qwen/Qwen-7B-Chat"
    local_dir = "./models/qwen-7b-chat"
    
    print(f"\nğŸ“¦ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
    print(f"ğŸ“ æœ¬åœ°ä¿å­˜è·¯å¾„: {local_dir}")
    
    start_time = time.time()
    
    try:
        # æ–¹æ³•1: ä½¿ç”¨snapshot_downloadæ‰¹é‡ä¸‹è½½
        print("\nğŸ”„ ä½¿ç”¨snapshot_downloadæ‰¹é‡ä¸‹è½½...")
        snapshot_download(
            repo_id=model_name,
            local_dir=local_dir,
            local_dir_use_symlinks=False,
            resume_download=True
        )
        print("âœ… æ¨¡å‹æ–‡ä»¶ä¸‹è½½å®Œæˆ")
        
        # æ–¹æ³•2: éªŒè¯ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹
        print("\nğŸ” éªŒè¯æ¨¡å‹å®Œæ•´æ€§...")
        tokenizer = AutoTokenizer.from_pretrained(local_dir)
        print("âœ… åˆ†è¯å™¨åŠ è½½æˆåŠŸ")
        
        # æ³¨æ„ï¼šè¿™é‡ŒåªéªŒè¯æ¨¡å‹é…ç½®ï¼Œä¸å®Œå…¨åŠ è½½ä»¥èŠ‚çœå†…å­˜
        from transformers import AutoConfig
        config = AutoConfig.from_pretrained(local_dir)
        print("âœ… æ¨¡å‹é…ç½®éªŒè¯æˆåŠŸ")
        
        end_time = time.time()
        duration = end_time - start_time
        print(f"\nğŸ‰ ä¸‹è½½å®Œæˆï¼æ€»è€—æ—¶: {duration:.2f}ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        print("\nğŸ”„ å°è¯•ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼ä¸‹è½½...")
        
        try:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä¼ ç»Ÿä¸‹è½½æ–¹å¼
            tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir="./models")
            print("âœ… åˆ†è¯å™¨ä¸‹è½½å®Œæˆ")
            
            # åªä¸‹è½½é…ç½®ï¼Œä¸ä¸‹è½½å®Œæ•´æ¨¡å‹ä»¥èŠ‚çœæ—¶é—´
            from transformers import AutoConfig
            config = AutoConfig.from_pretrained(model_name, cache_dir="./models")
            print("âœ… æ¨¡å‹é…ç½®ä¸‹è½½å®Œæˆ")
            
            end_time = time.time()
            duration = end_time - start_time
            print(f"\nğŸ‰ å¤‡ç”¨æ–¹æ¡ˆä¸‹è½½å®Œæˆï¼æ€»è€—æ—¶: {duration:.2f}ç§’")
            
            return True
            
        except Exception as e2:
            print(f"âŒ å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {str(e2)}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ Qwen-7B-Chat æ¨¡å‹å¿«é€Ÿä¸‹è½½å·¥å…·")
    print("=" * 60)
    
    # è®¾ç½®å¿«é€Ÿä¸‹è½½ç¯å¢ƒ
    setup_fast_download()
    
    # åˆ›å»ºæ¨¡å‹ç›®å½•
    os.makedirs("./models", exist_ok=True)
    
    # ä¸‹è½½æ¨¡å‹
    success = download_model_fast()
    
    if success:
        print("\n" + "=" * 60)
        print("ğŸ‰ æ¨¡å‹ä¸‹è½½æˆåŠŸï¼")
        print("ğŸ“ æ¥ä¸‹æ¥å¯ä»¥è¿è¡Œè®­ç»ƒè„šæœ¬:")
        print("   python scripts/train.py --config config/training_config.yaml")
        print("=" * 60)
    else:
        print("\n" + "=" * 60)
        print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼")
        print("ğŸ’¡ å»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
        print("=" * 60)

if __name__ == "__main__":
    main()